{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load lib/genotype_mixture\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "from pymc3.distributions.transforms import t_stick_breaking, logodds\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lib.util import info\n",
    "from lib.pileup import list_bases, get_pileup_dims\n",
    "import tqdm\n",
    "import theano.tensor as tt\n",
    "import theano.sparse as ts\n",
    "from itertools import product\n",
    "\n",
    "from lib.pymc3 import trace_stat_plot\n",
    "from arviz import ess\n",
    "from lib.genotype_mixture import gamma_plot, pi_plot\n",
    "\n",
    "stick_breaking = t_stick_breaking(1e-10)\n",
    "\n",
    "from lib.genotype_mixture import pileup_to_model_input\n",
    "from infer_strain_fractions import find_MAP_loop\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pymc3 as pm\n",
    "\n",
    "import logging\n",
    "pymc3_logger = logging.getLogger(\"pymc3\")\n",
    "\n",
    "\n",
    "def build_2strain_p(minor_frac):\n",
    "    return np.array([1 - minor_frac, minor_frac])\n",
    "\n",
    "def simulate_frac(n, p, alpha, random_state=None):\n",
    "    return sp.stats.dirichlet.rvs(alpha=p * alpha, size=n, random_state=random_state)\n",
    "\n",
    "def simulate_pileup(genotype, frac, cvrg, err_rate, random_state=None):\n",
    "    # Modified from lib.genotype_mixture.simulate_pileup to include random_state option.\n",
    "    g, s, a = genotype.shape\n",
    "    n, s2 = frac.shape\n",
    "    assert s == s2\n",
    "    g, n2 = cvrg.shape\n",
    "    assert n == n2\n",
    "\n",
    "    frac_allele = frac @ genotype\n",
    "    assert frac_allele.shape == (g, n, a)\n",
    "    prob_allele = (frac_allele * (1 - err_rate)\n",
    "                   + (1 - frac_allele) * (err_rate / (a - 1)))\n",
    "    assert np.allclose(prob_allele.sum(2), 1)\n",
    "\n",
    "    tally = np.empty_like(prob_allele)\n",
    "    for i in range(g):\n",
    "        for j in range(n):\n",
    "            tally[i, j, :] = sp.stats.multinomial.rvs(\n",
    "                cvrg[i, j],\n",
    "                prob_allele[i, j, :],\n",
    "                random_state=random_state,\n",
    "            )\n",
    "    assert (tally.sum(2) == cvrg).all()\n",
    "\n",
    "    pileup = []\n",
    "    for i in range(n):\n",
    "        pileup.append(pd.DataFrame(tally[:, i, :]).stack())\n",
    "    pileup = (pd.concat(pileup, axis=1)\n",
    "              .unstack(1)\n",
    "              .rename_axis(columns=('sample_id', 'base'), index='position'))\n",
    "    return pileup_to_model_input(pileup)\n",
    "\n",
    "def build_2strain_semi_informative_haplo(g1, g0):\n",
    "    haplotype = np.array([[1] * g1 + [0.5] * g0,\n",
    "                          [0] * g1 + [0.5] * g0]).T\n",
    "    haplotype = np.stack([haplotype, 1 - haplotype], axis=2)\n",
    "    return haplotype\n",
    "\n",
    "def simulate_simple_pileup(haplo, frac, m, error_rate, random_state=None):\n",
    "    g = haplo.shape[0]\n",
    "    n = frac.shape[0]\n",
    "    return simulate_pileup(haplo, frac, np.ones((g, n)) * m , error_rate, random_state=random_state)\n",
    "\n",
    "def simulate_simple_2strain_semi_informative(n, minor_frac, frac_conc, g1, g0, cvrg, error_rate, random_state):\n",
    "    expect_frac = build_2strain_p(minor_frac)\n",
    "    frac = simulate_frac(n, expect_frac, frac_conc, random_state=random_state)\n",
    "    haplotype = build_2strain_semi_informative_haplo(g1, g0)\n",
    "    pileup = simulate_simple_pileup(haplotype, frac, cvrg, error_rate, random_state=random_state)\n",
    "    return frac, haplotype, pileup\n",
    "\n",
    "def build_biallelic_model_fuzzy(g, n, s):\n",
    "    # EXPERIMENTAL: Observations overdispersed as a BetaBinom w/ concentrations\n",
    "    # 10.\n",
    "    a = 2\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # Fraction\n",
    "        pi = pm.Dirichlet('pi', a=np.ones(s), shape=(n, s),\n",
    "                          transform=stick_breaking,\n",
    "                          )\n",
    "        pi_hyper = pm.Data('pi_hyper', value=0.0)\n",
    "        pm.Potential('heterogeneity_penalty',\n",
    "                     -(pm.math.sqrt(pi).sum(0).sum()**2) * pi_hyper)\n",
    "\n",
    "        rho_hyper = pm.Data('rho_hyper', value=0.0)\n",
    "        pm.Potential('diversity_penalty',\n",
    "                     -(pm.math.sqrt(pi.sum(0)).sum()**2)\n",
    "                     * rho_hyper)\n",
    "\n",
    "        # Genotype\n",
    "        gamma_ = pm.Uniform('gamma_', 0, 1, shape=(g * s, 1))\n",
    "        gamma = pm.Deterministic('gamma', (pm.math.concatenate([gamma_, 1 - gamma_], axis=1)\n",
    "                                           .reshape((g, s, a))))\n",
    "        gamma_hyper = pm.Data('gamma_hyper', value=0.0)\n",
    "        pm.Potential('ambiguity_penalty',\n",
    "                     -((pm.math.sqrt(gamma).sum(2)**2).sum(0) * pi.sum(0)).sum(0)\n",
    "                     * gamma_hyper)\n",
    "\n",
    "        # Product of fraction and genotype\n",
    "        true_p = pm.Deterministic('true_p', pm.math.dot(pi, gamma))\n",
    "\n",
    "        # Sequencing error\n",
    "        epsilon_hyper = pm.Data('epsilon_hyper', value=100)\n",
    "        epsilon = pm.Beta('epsilon', alpha=2, beta=epsilon_hyper,\n",
    "                          shape=n)\n",
    "        epsilon_ = epsilon.reshape((n, 1, 1))\n",
    "        err_base_prob = tt.ones((n, g, a)) / a\n",
    "        p_with_error = (true_p * (1 - epsilon_)) + (err_base_prob * epsilon_)\n",
    "\n",
    "        # Observation\n",
    "        observed = pm.Data('observed', value=np.empty((g * n, a)))\n",
    "\n",
    "        _p = p_with_error.reshape((-1, a))[:, 0]\n",
    "        # Overdispersion term\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "        # TODO: Figure out how to also fit this term.\n",
    "        # FIXME: Do I want the default to be a valid value?\n",
    "        #  Realistic or close to asymptotic?\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "#         alpha = pm.Data('alpha', value=1000)\n",
    "#         pm.BetaBinomial('data',\n",
    "#                         alpha=_p * alpha,\n",
    "#                         beta=(1 - _p) * alpha,\n",
    "#                         n=observed.reshape((-1, a)).sum(1),\n",
    "#                         observed=observed[:,0])\n",
    "\n",
    "        # FIXME: This may not work as well as the\n",
    "        # highly concentrated BetaBinomial above.\n",
    "        pm.Binomial('data',\n",
    "                    p=_p,\n",
    "                    n=observed.reshape((-1, a)).sum(1),\n",
    "                    observed=observed[:,0])\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_biallelic_model_discrete(g, n, s):\n",
    "    # Discrete haplotypes.\n",
    "    a = 2\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # Fraction\n",
    "        pi = pm.Dirichlet('pi', a=np.ones(s), shape=(n, s),\n",
    "                          transform=stick_breaking,\n",
    "                          )\n",
    "        pi_hyper = pm.Data('pi_hyper', value=0.0)\n",
    "        pm.Potential('heterogeneity_penalty',\n",
    "                     -(pm.math.sqrt(pi).sum(0).sum()**2) * pi_hyper)\n",
    "\n",
    "        rho_hyper = pm.Data('rho_hyper', value=0.0)\n",
    "        pm.Potential('diversity_penalty',\n",
    "                     -(pm.math.sqrt(pi.sum(0)).sum()**2)\n",
    "                     * rho_hyper)\n",
    "\n",
    "        # Genotype\n",
    "        gamma_ = pm.Bernoulli('gamma_', p=0.5, shape=(g * s, 1))\n",
    "        gamma = pm.Deterministic('gamma', (pm.math.concatenate([gamma_, 1 - gamma_], axis=1)\n",
    "                                           .reshape((g, s, a))))\n",
    "        gamma_hyper = pm.Data('gamma_hyper', value=0.0)\n",
    "        pm.Potential('ambiguity_penalty',\n",
    "                     -((pm.math.sqrt(gamma).sum(2)**2).sum(0) * pi.sum(0)).sum(0)\n",
    "                     * gamma_hyper)\n",
    "\n",
    "        # Product of fraction and genotype\n",
    "        true_p = pm.Deterministic('true_p', pm.math.dot(pi, gamma))\n",
    "\n",
    "        # Sequencing error\n",
    "        epsilon_hyper = pm.Data('epsilon_hyper', value=100)\n",
    "        epsilon = pm.Beta('epsilon', alpha=2, beta=epsilon_hyper,\n",
    "                          shape=n)\n",
    "        epsilon_ = epsilon.reshape((n, 1, 1))\n",
    "        err_base_prob = tt.ones((n, g, a)) / a\n",
    "        p_with_error = (true_p * (1 - epsilon_)) + (err_base_prob * epsilon_)\n",
    "\n",
    "        # Observation\n",
    "        observed = pm.Data('observed', value=np.empty((g * n, a)))\n",
    "\n",
    "        _p = p_with_error.reshape((-1, a))[:, 0]\n",
    "        # Overdispersion term\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "        # TODO: Figure out how to also fit this term.\n",
    "        # FIXME: Do I want the default to be a valid value?\n",
    "        #  Realistic or close to asymptotic?\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "#         alpha = pm.Data('alpha', value=1000)\n",
    "#         pm.BetaBinomial('data',\n",
    "#                         alpha=_p * alpha,\n",
    "#                         beta=(1 - _p) * alpha,\n",
    "#                         n=observed.reshape((-1, a)).sum(1),\n",
    "#                         observed=observed[:,0])\n",
    "\n",
    "        # FIXME: This may not work as well as the\n",
    "        # highly concentrated BetaBinomial above.\n",
    "        pm.Binomial('data',\n",
    "                    p=_p,\n",
    "                    n=observed.reshape((-1, a)).sum(1),\n",
    "                    observed=observed[:,0])\n",
    "\n",
    "    return model\n",
    "\n",
    "def select_permutation_greedy(data, ref, axis, key=None):\n",
    "    index_swap = (0, axis)\n",
    "    data = np.swapaxes(data, *index_swap)\n",
    "    ref = np.swapaxes(ref, *index_swap)\n",
    "    \n",
    "    if key is None:\n",
    "        key = lambda x, y: (np.abs(x - y)**2).sum()\n",
    "\n",
    "    data_idx = np.arange(data.shape[0])\n",
    "    ref_idx = np.arange(ref.shape[0])\n",
    "    \n",
    "    perm = []\n",
    "    for i in ref_idx:\n",
    "        best_data_idx = 0\n",
    "        best_data_loss = np.inf\n",
    "        for j in data_idx:\n",
    "            if j in perm:\n",
    "                continue\n",
    "            loss = key(ref[i], data[j])\n",
    "            if loss < best_data_loss:\n",
    "                best_data_idx = j\n",
    "                best_data_loss = loss\n",
    "        perm.append(best_data_idx)\n",
    "    \n",
    "    for j in data_idx:\n",
    "        if j not in perm:\n",
    "            perm.append(j)\n",
    "    \n",
    "    return perm\n",
    "\n",
    "def sample_both_models(pileup, s, gamma_hyper, pi_hyper, rho_hyper, epsilon_hyper, chains=5, **kwargs):\n",
    "    n, g, a = pileup.shape\n",
    "    model_disc = build_biallelic_model_discrete(g, n, s)\n",
    "    model_disc.observed.set_value(pileup.reshape((-1, a)))\n",
    "    model_disc.gamma_hyper.set_value(gamma_hyper)  # Does not affect discrete model\n",
    "    model_disc.pi_hyper.set_value(pi_hyper)\n",
    "    model_disc.rho_hyper.set_value(rho_hyper)\n",
    "    model_disc.epsilon_hyper.set_value(epsilon_hyper)\n",
    "    \n",
    "    pymc3_logger.setLevel(logging.ERROR)\n",
    "    \n",
    "    with model_disc:\n",
    "        trace_disc = pm.sample(\n",
    "            chains=chains, cores=chains,\n",
    "            step=[\n",
    "                pm.step_methods.BinaryGibbsMetropolis(\n",
    "                    vars=[model_disc.gamma_],\n",
    "                    transit_p=0.75\n",
    "                ),\n",
    "            ],\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    model_fuzz = build_biallelic_model_fuzzy(g, n, s)\n",
    "    model_fuzz.observed.set_value(pileup.reshape((-1, a)))\n",
    "    model_fuzz.gamma_hyper.set_value(gamma_hyper)\n",
    "    model_fuzz.pi_hyper.set_value(pi_hyper)\n",
    "    model_fuzz.rho_hyper.set_value(rho_hyper)\n",
    "    model_fuzz.epsilon_hyper.set_value(epsilon_hyper)\n",
    "    with model_fuzz:\n",
    "        trace_fuzz = pm.sample(\n",
    "            chains=chains, cores=chains,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    pymc3_logger.setLevel(logging.INFO)\n",
    "\n",
    "    return trace_disc, trace_fuzz\n",
    "\n",
    "def score_sampled_frac_estimate(trace, true, i):\n",
    "    expect = np.mean(trace['pi'], axis=0)\n",
    "    permute = select_permutation_greedy(expect, true, axis=1)\n",
    "    expect_i = expect[:, permute[i]]\n",
    "    return (np.mean((expect_i - true[:,i])**2))**(1/2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n = 10\n",
    "minor_frac = 0.02\n",
    "expect_frac = build_2strain_p(minor_frac)\n",
    "frac_conc = 10\n",
    "m = 2\n",
    "# a = 2\n",
    "g0 = 5  # Noisy positions\n",
    "g1 = 50\n",
    "g = g1 + g0\n",
    "error_rate = 0.01\n",
    "\n",
    "random_state = np.random.RandomState(8)\n",
    "frac, haplo, pileup = simulate_simple_2strain_semi_informative(\n",
    "    n, minor_frac, frac_conc, g1, g0, m, error_rate, random_state=random_state\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "pi_plot(frac, pwr=1/2)\n",
    "gamma_plot(haplo)\n",
    "y = pileup.swapaxes(0, 1)\n",
    "y = y / y.sum(2, keepdims=True)\n",
    "gamma_plot(y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trace_disc, trace_fuzz = sample_both_models(pileup, s=2, gamma_hyper=1, pi_hyper=0, rho_hyper=1, epsilon_hyper=200, random_seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_stat_plot(trace_discrete, 'model_logp')\n",
    "pi_chain = np.concatenate(list(p['pi'] for p in trace_discrete.points(chains=[0])))\n",
    "pi_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "minor_frac = 0.05\n",
    "frac_conc = 10\n",
    "g1 = 50  # Informative positions\n",
    "error_rate = 0.01\n",
    "\n",
    "\n",
    "results = []\n",
    "for s_fit in [2, 3]:\n",
    "    for g0 in [0, 1, 5]:\n",
    "        for minor_frac in [0.4, 0.2, 0.05, 0.02, 0.01]:\n",
    "            for m in [50, 10, 2]:\n",
    "                for sim_seed in [5]:\n",
    "                    random_state = np.random.RandomState(sim_seed)\n",
    "                    frac, haplo, pileup = simulate_simple_2strain_semi_informative(\n",
    "                        n=n,\n",
    "                        minor_frac=minor_frac,\n",
    "                        frac_conc=frac_conc,\n",
    "                        g1=g1,\n",
    "                        g0=g0,\n",
    "                        cvrg=m,\n",
    "                        error_rate=error_rate,\n",
    "                        random_state=random_state,\n",
    "                    )\n",
    "                    trace_disc, trace_fuzz = sample_both_models(\n",
    "                        pileup,\n",
    "                        s=s_fit,\n",
    "                        gamma_hyper=1,\n",
    "                        pi_hyper=0,\n",
    "                        rho_hyper=1,\n",
    "                        epsilon_hyper=200,\n",
    "                        random_seed=1,\n",
    "                        chains=8,\n",
    "                        progressbar=False,\n",
    "                        compute_convergence_checks=False,\n",
    "                    )\n",
    "                    results.append((\n",
    "                        s_fit,\n",
    "                        g0,\n",
    "                        minor_frac,\n",
    "                        m,\n",
    "                        sim_seed,\n",
    "                        score_sampled_frac_estimate(trace_disc, frac, 1),\n",
    "                        score_sampled_frac_estimate(trace_fuzz, frac, 1),\n",
    "                    ))\n",
    "                    print(results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_stat_plot(trace_disc, 'model_logp')\n",
    "\n",
    "def get_single_chain_values(trace, chains, var):\n",
    "    return np.stack(\n",
    "        list(\n",
    "            p[var]\n",
    "            for p\n",
    "            in trace.points(chains=chains)\n",
    "        )\n",
    "    )\n",
    "\n",
    "for chain in range(1):\n",
    "    plt.plot(get_single_chain_values(trace_disc, chains=[chain], var='pi')[:,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_disc.get_sampler_stats('model_logp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_chain_with_best_terminus(trace):\n",
    "    trace.model_logp[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_strain_fractions import find_MAP_loop_retry\n",
    "\n",
    "find_MAP_loop_retry??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trace_disc.epsilon.mean(0), label='discrete', color='green')\n",
    "plt.plot(trace_fuzz.epsilon.mean(0), label='fuzzy', color='blue')\n",
    "# plt.plot(mapest_fuzzy['epsilon'], label='fuzzy_mapest', color='darkblue')\n",
    "# plt.plot(trace_fuzzy_dp.epsilon.mean(0), label='fuzzy_dp', color='aqua')\n",
    "# plt.plot(trace_discrete_dp.epsilon.mean(0), label='discrete_dp', color='lightgreen')\n",
    "\n",
    "\n",
    "plt.axhline(1e-2, lw=1, linestyle='--', color='k')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_stat_plot(trace_fuzz, 'model_logp')\n",
    "trace_stat_plot(trace_disc, 'model_logp')\n",
    "\n",
    "(\n",
    "    ess(trace_fuzz.model_logp),\n",
    "    ess(trace_disc.model_logp),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_plot(frac, pwr=1/2)\n",
    "gamma_plot(haplo)\n",
    "y = pileup.swapaxes(0, 1)\n",
    "y = y / y.sum(2, keepdims=True)\n",
    "gamma_plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_expect_fuzz = np.median(trace_fuzz['pi'], axis=0)\n",
    "_expect_disc = np.median(trace_disc['pi'], axis=0)\n",
    "\n",
    "permute_disc = select_permutation_greedy(_expect_disc, frac, axis=1)\n",
    "permute_fuzz = select_permutation_greedy(_expect_fuzz, frac, axis=1)\n",
    "\n",
    "pi_plot(frac, pwr=1/2)\n",
    "pi_plot(_expect_disc[:,permute_disc], pwr=1/2)\n",
    "pi_plot(_expect_fuzz[:,permute_fuzz], pwr=1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_expect_fuzz = trace_fuzz['gamma'].mean(0)\n",
    "_expect_disc = trace_disc['gamma'].mean(0)\n",
    "\n",
    "gamma_plot(haplo)\n",
    "gamma_plot(_expect_disc[:,permute_disc])\n",
    "gamma_plot(_expect_fuzz[:,permute_fuzz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "_true = frac[:,j]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 10))\n",
    "\n",
    "ax.scatter(_true, range(n), color='k', marker='x', label='true')\n",
    "\n",
    "for pi, name, color, offset in [\n",
    "                        (trace_fuzz.pi[:,:,permute_fuzz], 'fuzz', 'blue', +0.1),\n",
    "                        (trace_disc.pi[:,:,permute_disc], 'disc', 'green', -0.1),\n",
    "                       ]:\n",
    "    ax.scatter(np.quantile(pi, 0.5, axis=0)[:,j], np.arange(n) + offset, color=color, marker='^', label=name)\n",
    "    print(name, np.sqrt(np.mean(np.square(np.quantile(pi, 0.5, axis=0)[:,j] - _true))))\n",
    "    ax.hlines(np.arange(n) + offset, np.quantile(pi, 0.25, axis=0)[:,j], np.quantile(pi, 0.75, axis=0)[:,j], lw=1, color=color)\n",
    "    ax.hlines(np.arange(n) + offset, np.quantile(pi, 0.05, axis=0)[:,j], np.quantile(pi, 0.95, axis=0)[:,j], lw=0.5, color=color)\n",
    "    ax.hlines(np.arange(n) + offset, np.quantile(pi, 0.01, axis=0)[:,j], np.quantile(pi, 0.99, axis=0)[:,j], lw=0.25, color=color)\n",
    "ax.legend(bbox_to_anchor=(1.25, 1))\n",
    "#ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}