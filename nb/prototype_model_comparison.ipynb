{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype PyMC3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load lib/genotype_mixture\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "from pymc3.distributions.transforms import t_stick_breaking, logodds\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lib.util import info\n",
    "from lib.pileup import list_bases, get_pileup_dims\n",
    "import tqdm\n",
    "import theano.tensor as tt\n",
    "import theano.sparse as ts\n",
    "from itertools import product\n",
    "\n",
    "from lib.pymc3 import trace_stat_plot\n",
    "from arviz import ess\n",
    "from lib.genotype_mixture import gamma_plot, pi_plot\n",
    "\n",
    "\n",
    "\n",
    "stick_breaking = t_stick_breaking(1e-10)\n",
    "\n",
    "\n",
    "def build_biallelic_model_fuzzy(g, n, s):\n",
    "    # EXPERIMENTAL: Observations overdispersed as a BetaBinom w/ concentrations\n",
    "    # 10.\n",
    "    a = 2\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # Fraction\n",
    "        pi = pm.Dirichlet('pi', a=np.ones(s), shape=(n, s),\n",
    "                          transform=stick_breaking,\n",
    "                          )\n",
    "        pi_hyper = pm.Data('pi_hyper', value=0.0)\n",
    "        pm.Potential('heterogeneity_penalty',\n",
    "                     -(pm.math.sqrt(pi).sum(0).sum()**2) * pi_hyper)\n",
    "\n",
    "        rho_hyper = pm.Data('rho_hyper', value=0.0)\n",
    "        pm.Potential('diversity_penalty',\n",
    "                     -(pm.math.sqrt(pi.sum(0)).sum()**2)\n",
    "                     * rho_hyper)\n",
    "\n",
    "        # Genotype\n",
    "        gamma_ = pm.Uniform('gamma_', 0, 1, shape=(g * s, 1))\n",
    "        gamma = pm.Deterministic('gamma', (pm.math.concatenate([gamma_, 1 - gamma_], axis=1)\n",
    "                                           .reshape((g, s, a))))\n",
    "        gamma_hyper = pm.Data('gamma_hyper', value=0.0)\n",
    "        pm.Potential('ambiguity_penalty',\n",
    "                     -((pm.math.sqrt(gamma).sum(2)**2).sum(0) * pi.sum(0)).sum(0)\n",
    "                     * gamma_hyper)\n",
    "\n",
    "        # Product of fraction and genotype\n",
    "        true_p = pm.Deterministic('true_p', pm.math.dot(pi, gamma))\n",
    "\n",
    "        # Sequencing error\n",
    "        epsilon_hyper = pm.Data('epsilon_hyper', value=100)\n",
    "        epsilon = pm.Beta('epsilon', alpha=2, beta=epsilon_hyper,\n",
    "                          shape=n)\n",
    "        epsilon_ = epsilon.reshape((n, 1, 1))\n",
    "        err_base_prob = tt.ones((n, g, a)) / a\n",
    "        p_with_error = (true_p * (1 - epsilon_)) + (err_base_prob * epsilon_)\n",
    "\n",
    "        # Observation\n",
    "        observed = pm.Data('observed', value=np.empty((g * n, a)))\n",
    "\n",
    "        _p = p_with_error.reshape((-1, a))[:, 0]\n",
    "        # Overdispersion term\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "        # TODO: Figure out how to also fit this term.\n",
    "        # FIXME: Do I want the default to be a valid value?\n",
    "        #  Realistic or close to asymptotic?\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "#         alpha = pm.Data('alpha', value=1000)\n",
    "#         pm.BetaBinomial('data',\n",
    "#                         alpha=_p * alpha,\n",
    "#                         beta=(1 - _p) * alpha,\n",
    "#                         n=observed.reshape((-1, a)).sum(1),\n",
    "#                         observed=observed[:,0])\n",
    "\n",
    "        # FIXME: This may not work as well as the\n",
    "        # highly concentrated BetaBinomial above.\n",
    "        pm.Binomial('data',\n",
    "                    p=_p,\n",
    "                    n=observed.reshape((-1, a)).sum(1),\n",
    "                    observed=observed[:,0])\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_biallelic_model_discrete(g, n, s):\n",
    "    # Discrete haplotypes.\n",
    "    a = 2\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # Fraction\n",
    "        pi = pm.Dirichlet('pi', a=np.ones(s), shape=(n, s),\n",
    "                          transform=stick_breaking,\n",
    "                          )\n",
    "        pi_hyper = pm.Data('pi_hyper', value=0.0)\n",
    "        pm.Potential('heterogeneity_penalty',\n",
    "                     -(pm.math.sqrt(pi).sum(0).sum()**2) * pi_hyper)\n",
    "\n",
    "        rho_hyper = pm.Data('rho_hyper', value=0.0)\n",
    "        pm.Potential('diversity_penalty',\n",
    "                     -(pm.math.sqrt(pi.sum(0)).sum()**2)\n",
    "                     * rho_hyper)\n",
    "\n",
    "        # Genotype\n",
    "        gamma_ = pm.Bernoulli('gamma_', p=0.5, shape=(g * s, 1))\n",
    "        gamma = pm.Deterministic('gamma', (pm.math.concatenate([gamma_, 1 - gamma_], axis=1)\n",
    "                                           .reshape((g, s, a))))\n",
    "        gamma_hyper = pm.Data('gamma_hyper', value=0.0)\n",
    "        pm.Potential('ambiguity_penalty',\n",
    "                     -((pm.math.sqrt(gamma).sum(2)**2).sum(0) * pi.sum(0)).sum(0)\n",
    "                     * gamma_hyper)\n",
    "\n",
    "        # Product of fraction and genotype\n",
    "        true_p = pm.Deterministic('true_p', pm.math.dot(pi, gamma))\n",
    "\n",
    "        # Sequencing error\n",
    "        epsilon_hyper = pm.Data('epsilon_hyper', value=100)\n",
    "        epsilon = pm.Beta('epsilon', alpha=2, beta=epsilon_hyper,\n",
    "                          shape=n)\n",
    "        epsilon_ = epsilon.reshape((n, 1, 1))\n",
    "        err_base_prob = tt.ones((n, g, a)) / a\n",
    "        p_with_error = (true_p * (1 - epsilon_)) + (err_base_prob * epsilon_)\n",
    "\n",
    "        # Observation\n",
    "        observed = pm.Data('observed', value=np.empty((g * n, a)))\n",
    "\n",
    "        _p = p_with_error.reshape((-1, a))[:, 0]\n",
    "        # Overdispersion term\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "        # TODO: Figure out how to also fit this term.\n",
    "        # FIXME: Do I want the default to be a valid value?\n",
    "        #  Realistic or close to asymptotic?\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "#         alpha = pm.Data('alpha', value=1000)\n",
    "#         pm.BetaBinomial('data',\n",
    "#                         alpha=_p * alpha,\n",
    "#                         beta=(1 - _p) * alpha,\n",
    "#                         n=observed.reshape((-1, a)).sum(1),\n",
    "#                         observed=observed[:,0])\n",
    "\n",
    "        # FIXME: This may not work as well as the\n",
    "        # highly concentrated BetaBinomial above.\n",
    "        pm.Binomial('data',\n",
    "                    p=_p,\n",
    "                    n=observed.reshape((-1, a)).sum(1),\n",
    "                    observed=observed[:,0])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def dirichlet_process_rv(prefix, k):\n",
    "    alpha = pm.Gamma(prefix + '_alpha', 1., 1.)\n",
    "    beta = pm.Beta(prefix + '_beta', 1., alpha, shape=k)\n",
    "    w = pm.Deterministic(\n",
    "        prefix + '',\n",
    "        beta * tt.concatenate([[1], tt.extra_ops.cumprod(1 - beta)[:-1]])\n",
    "    )\n",
    "    return w\n",
    "\n",
    "\n",
    "def build_biallelic_model_fuzzy_dp(g, n, s):\n",
    "    # EXPERIMENTAL: Observations overdispersed as a BetaBinom w/ concentrations\n",
    "    # 10.\n",
    "    a = 2\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        pi_w = dirichlet_process_rv('pi_w', s)\n",
    "        pi_alpha = 100\n",
    "        pi = pm.Dirichlet('pi', a=pi_w * pi_alpha, shape=(n, s),\n",
    "                          transform=stick_breaking,\n",
    "                          testval=np.ones((n, s))/s  # Uniform\n",
    "                          )\n",
    "        pi_hyper = pm.Data('pi_hyper', value=0.0)\n",
    "        pm.Potential('heterogeneity_penalty',\n",
    "                     -(pm.math.sqrt(pi).sum(0).sum()**2) * pi_hyper)\n",
    "\n",
    "        rho_hyper = pm.Data('rho_hyper', value=0.0)\n",
    "        pm.Potential('diversity_penalty',\n",
    "                     -(pm.math.sqrt(pi.sum(0)).sum()**2)\n",
    "                     * rho_hyper)\n",
    "\n",
    "        # Genotype\n",
    "        gamma_ = pm.Uniform('gamma_', 0, 1, shape=(g * s, 1))\n",
    "        gamma = pm.Deterministic('gamma', (pm.math.concatenate([gamma_, 1 - gamma_], axis=1)\n",
    "                                           .reshape((g, s, a))))\n",
    "        gamma_hyper = pm.Data('gamma_hyper', value=0.0)\n",
    "        pm.Potential('ambiguity_penalty',\n",
    "                     -((pm.math.sqrt(gamma).sum(2)**2).sum(0) * pi.sum(0)).sum(0)\n",
    "                     * gamma_hyper)\n",
    "\n",
    "        # Product of fraction and genotype\n",
    "        true_p = pm.Deterministic('true_p', pm.math.dot(pi, gamma))\n",
    "\n",
    "        # Sequencing error\n",
    "        epsilon_hyper = pm.Data('epsilon_hyper', value=100)\n",
    "        epsilon = pm.Beta('epsilon', alpha=2, beta=epsilon_hyper,\n",
    "                          shape=n)\n",
    "        epsilon_ = epsilon.reshape((n, 1, 1))\n",
    "        err_base_prob = tt.ones((n, g, a)) / a\n",
    "        p_with_error = (true_p * (1 - epsilon_)) + (err_base_prob * epsilon_)\n",
    "\n",
    "        # Observation\n",
    "        _p = p_with_error.reshape((-1, a))[:, 0]\n",
    "        # Overdispersion term\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "        # TODO: Figure out how to also fit this term.\n",
    "        # FIXME: Do I want the default to be a valid value?\n",
    "        #  Realistic or close to asymptotic?\n",
    "        alpha = pm.Data('alpha', value=1000)\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "\n",
    "        observed = pm.Data('observed', value=np.empty((g * n, a)))\n",
    "        pm.BetaBinomial('data',\n",
    "                        alpha=_p * alpha,\n",
    "                        beta=(1 - _p) * alpha,\n",
    "                        n=observed.reshape((-1, a)).sum(1),\n",
    "                        observed=observed[:,0])\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_biallelic_model_discrete_dp(g, n, s):\n",
    "    # EXPERIMENTAL: Observations overdispersed as a BetaBinom w/ concentrations\n",
    "    # 10.\n",
    "    a = 2\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        pi_w = dirichlet_process_rv('pi_w', s)\n",
    "        pi_alpha = 100\n",
    "        pi = pm.Dirichlet('pi', a=pi_w * pi_alpha, shape=(n, s),\n",
    "                          transform=stick_breaking,\n",
    "                          testval=np.ones((n, s))/s  # Uniform\n",
    "                          )\n",
    "        pi_hyper = pm.Data('pi_hyper', value=0.0)\n",
    "        pm.Potential('heterogeneity_penalty',\n",
    "                     -(pm.math.sqrt(pi).sum(0).sum()**2) * pi_hyper)\n",
    "\n",
    "        rho_hyper = pm.Data('rho_hyper', value=0.0)\n",
    "        pm.Potential('diversity_penalty',\n",
    "                     -(pm.math.sqrt(pi.sum(0)).sum()**2)\n",
    "                     * rho_hyper)\n",
    "\n",
    "        # Genotype\n",
    "        gamma_ = pm.Bernoulli('gamma_', p=0.5, shape=(g * s, 1))\n",
    "        gamma = pm.Deterministic('gamma', (pm.math.concatenate([gamma_, 1 - gamma_], axis=1)\n",
    "                                           .reshape((g, s, a))))\n",
    "        gamma_hyper = pm.Data('gamma_hyper', value=0.0)\n",
    "        pm.Potential('ambiguity_penalty',\n",
    "                     -((pm.math.sqrt(gamma).sum(2)**2).sum(0) * pi.sum(0)).sum(0)\n",
    "                     * gamma_hyper)\n",
    "\n",
    "        # Product of fraction and genotype\n",
    "        true_p = pm.Deterministic('true_p', pm.math.dot(pi, gamma))\n",
    "\n",
    "        # Sequencing error\n",
    "        epsilon_hyper = pm.Data('epsilon_hyper', value=100)\n",
    "        epsilon = pm.Beta('epsilon', alpha=2, beta=epsilon_hyper,\n",
    "                          shape=n)\n",
    "        epsilon_ = epsilon.reshape((n, 1, 1))\n",
    "        err_base_prob = tt.ones((n, g, a)) / a\n",
    "        p_with_error = (true_p * (1 - epsilon_)) + (err_base_prob * epsilon_)\n",
    "\n",
    "        # Observation\n",
    "        _p = p_with_error.reshape((-1, a))[:, 0]\n",
    "        # Overdispersion term\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "        # TODO: Figure out how to also fit this term.\n",
    "        # FIXME: Do I want the default to be a valid value?\n",
    "        #  Realistic or close to asymptotic?\n",
    "        alpha = pm.Data('alpha', value=1000)\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "\n",
    "        observed = pm.Data('observed', value=np.empty((g * n, a)))\n",
    "        pm.BetaBinomial('data',\n",
    "                        alpha=_p * alpha,\n",
    "                        beta=(1 - _p) * alpha,\n",
    "                        n=observed.reshape((-1, a)).sum(1),\n",
    "                        observed=observed[:,0])\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_biallelic_model_fuzzy_hd(g, n, s):\n",
    "    # EXPERIMENTAL: Observations overdispersed as a BetaBinom w/ concentrations\n",
    "    # 10.\n",
    "    a = 2\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # Fraction\n",
    "        rho_hyper = pm.Normal('rho_hyper', sigma=1)  # pm.Data('rho_hyper', value=0.0)\n",
    "        rho = pm.Dirichlet(\n",
    "            'rho',\n",
    "            a=tt.ones(s) * pm.math.exp(-rho_hyper),\n",
    "            transform=stick_breaking,\n",
    "            shape=(s,),\n",
    "        )\n",
    "        pi_hyper = pm.Normal('pi_hyper', sigma=1)  # pm.Data('pi_hyper', value=0.0)\n",
    "        pi = pm.Dirichlet(\n",
    "            'pi',\n",
    "            a=rho * pm.math.exp(-pi_hyper),\n",
    "            shape=(n, s),\n",
    "            transform=stick_breaking,\n",
    "        )\n",
    "\n",
    "        # Genotype\n",
    "        gamma_ = pm.Uniform('gamma_', 0, 1, shape=(g * s, 1))\n",
    "        gamma = pm.Deterministic('gamma', (pm.math.concatenate([gamma_, 1 - gamma_], axis=1)\n",
    "                                           .reshape((g, s, a))))\n",
    "        gamma_hyper = pm.Data('gamma_hyper', value=0.0)\n",
    "        pm.Potential('ambiguity_penalty',\n",
    "                     -((pm.math.sqrt(gamma).sum(2)**2).sum(0) * pi.sum(0)).sum(0)\n",
    "                     * gamma_hyper)\n",
    "\n",
    "        # Product of fraction and genotype\n",
    "        true_p = pm.Deterministic('true_p', pm.math.dot(pi, gamma))\n",
    "\n",
    "        # Sequencing error\n",
    "        epsilon_hyper = pm.Data('epsilon_hyper', value=100)\n",
    "        epsilon = pm.Beta('epsilon', alpha=2, beta=epsilon_hyper,\n",
    "                          shape=n)\n",
    "        epsilon_ = epsilon.reshape((n, 1, 1))\n",
    "        err_base_prob = tt.ones((n, g, a)) / a\n",
    "        p_with_error = (true_p * (1 - epsilon_)) + (err_base_prob * epsilon_)\n",
    "\n",
    "        # Observation\n",
    "        _p = p_with_error.reshape((-1, a))[:, 0]\n",
    "        # Overdispersion term\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "        # TODO: Figure out how to also fit this term.\n",
    "        # FIXME: Do I want the default to be a valid value?\n",
    "        #  Realistic or close to asymptotic?\n",
    "        alpha = pm.Data('alpha', value=1000)\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "\n",
    "        observed = pm.Data('observed', value=np.empty((g * n, a)))\n",
    "        pm.BetaBinomial('data',\n",
    "                        alpha=_p * alpha,\n",
    "                        beta=(1 - _p) * alpha,\n",
    "                        n=observed.reshape((-1, a)).sum(1),\n",
    "                        observed=observed[:,0])\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_biallelic_model_discrete_hd(g, n, s):\n",
    "    # Discrete haplotypes.\n",
    "    a = 2\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # Fraction\n",
    "        rho_hyper = pm.Normal('rho_hyper', sigma=1)  # pm.Data('rho_hyper', value=0.0)\n",
    "        rho = pm.Dirichlet(\n",
    "            'rho',\n",
    "            a=tt.ones(s) * pm.math.exp(-rho_hyper),\n",
    "            transform=stick_breaking,\n",
    "            shape=(s,),\n",
    "        )\n",
    "        pi_hyper = pm.Normal('pi_hyper', sigma=1)  # pm.Data('pi_hyper', value=0.0)\n",
    "        pi = pm.Dirichlet(\n",
    "            'pi',\n",
    "            a=rho * pm.math.exp(-pi_hyper),\n",
    "            shape=(n, s),\n",
    "            transform=stick_breaking,\n",
    "        )\n",
    "\n",
    "        # Genotype\n",
    "        gamma_ = pm.Bernoulli('gamma_', p=0.5, shape=(g * s, 1))\n",
    "        gamma = pm.Deterministic('gamma', (pm.math.concatenate([gamma_, 1 - gamma_], axis=1)\n",
    "                                           .reshape((g, s, a))))\n",
    "        gamma_hyper = pm.Data('gamma_hyper', value=0.0)\n",
    "        pm.Potential('ambiguity_penalty',\n",
    "                     -((pm.math.sqrt(gamma).sum(2)**2).sum(0) * pi.sum(0)).sum(0)\n",
    "                     * gamma_hyper)\n",
    "\n",
    "        # Product of fraction and genotype\n",
    "        true_p = pm.Deterministic('true_p', pm.math.dot(pi, gamma))\n",
    "\n",
    "        # Sequencing error\n",
    "        epsilon_hyper = pm.Data('epsilon_hyper', value=100)\n",
    "        epsilon = pm.Beta('epsilon', alpha=2, beta=epsilon_hyper,\n",
    "                          shape=n)\n",
    "        epsilon_ = epsilon.reshape((n, 1, 1))\n",
    "        err_base_prob = tt.ones((n, g, a)) / a\n",
    "        p_with_error = (true_p * (1 - epsilon_)) + (err_base_prob * epsilon_)\n",
    "\n",
    "        # Observation\n",
    "        _p = p_with_error.reshape((-1, a))[:, 0]\n",
    "        # Overdispersion term\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "        # TODO: Figure out how to also fit this term.\n",
    "        # FIXME: Do I want the default to be a valid value?\n",
    "        #  Realistic or close to asymptotic?\n",
    "        alpha = pm.Data('alpha', value=1000)\n",
    "        # alpha = pm.Gamma('alpha', mu=100, sigma=5)\n",
    "\n",
    "        observed = pm.Data('observed', value=np.empty((g * n, a)))\n",
    "        pm.BetaBinomial('data',\n",
    "                        alpha=_p * alpha,\n",
    "                        beta=(1 - _p) * alpha,\n",
    "                        n=observed.reshape((-1, a)).sum(1),\n",
    "                        observed=observed[:,0])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.genotype_mixture import simulate_pileup, pileup_to_model_input\n",
    "from scripts.infer_strain_fractions import find_MAP_loop\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pymc3 as pm\n",
    "\n",
    "n = 10\n",
    "dom_frac = 0.98\n",
    "avg_frac = np.array([dom_frac, 1 - dom_frac])\n",
    "frac_conc = 10\n",
    "frac = sp.stats.dirichlet.rvs(alpha=avg_frac * frac_conc, size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_plot(frac, pwr=1/2)\n",
    "frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 30\n",
    "a = 2\n",
    "g0 = 5  # Noisy positions\n",
    "g1 = 50\n",
    "g = g1 + g0\n",
    "error_rate = 0.01\n",
    "haplotype = np.array([[1] * g1 + [0.5] * g0,\n",
    "                      [0] * g1 + [0.5] * g0]).T\n",
    "haplotype = np.stack([haplotype, 1 - haplotype], axis=2)\n",
    "\n",
    "pileup = simulate_pileup(haplotype, frac, np.ones((g, n)) * m , error_rate)\n",
    "\n",
    "# Visualize\n",
    "gamma_plot(haplotype)\n",
    "\n",
    "y = pileup_to_model_input(pileup).swapaxes(0, 1)\n",
    "y = y / y.sum(2, keepdims=True)\n",
    "gamma_plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_discrete = build_biallelic_model_discrete(g, n, 3)\n",
    "model_discrete.observed.set_value(pileup_to_model_input(pileup).reshape((-1, a)))\n",
    "#model_discrete.alpha.set_value(1e5)\n",
    "model_discrete.gamma_hyper.set_value(1)\n",
    "model_discrete.pi_hyper.set_value(0)\n",
    "model_discrete.rho_hyper.set_value(1)\n",
    "model_discrete.epsilon_hyper.set_value(200)\n",
    "\n",
    "\n",
    "with model_discrete:\n",
    "    trace_discrete = pm.sample(chains=1,\n",
    "#                             tune=2500,\n",
    "#                             draws=1000,\n",
    "#                            discard_tuned_samples=False,\n",
    "                               step=[pm.step_methods.BinaryGibbsMetropolis(vars=[model_discrete.gamma_],\n",
    "                                                                           transit_p=0.5),\n",
    "#                                      pm.step_methods.NUTS(vars=[model_discrete.epsilon, model_discrete.pi, model_discrete.pi_hyper, model_discrete.rho, model_discrete.rho_hyper], max_treedepth=6)\n",
    "                                    ]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fuzzy = build_biallelic_model_fuzzy(g, n, 3)\n",
    "model_fuzzy.observed.set_value(pileup_to_model_input(pileup).reshape((-1, a)))\n",
    "#model_fuzzy.alpha.set_value(1e5)\n",
    "model_fuzzy.gamma_hyper.set_value(1)\n",
    "model_fuzzy.pi_hyper.set_value(0)\n",
    "model_fuzzy.rho_hyper.set_value(1)\n",
    "model_fuzzy.epsilon_hyper.set_value(200)\n",
    "\n",
    "with model_fuzzy:\n",
    "    trace_fuzzy = pm.sample(chains=1,\n",
    "#                             tune=2500,\n",
    "#                             draws=1000,\n",
    "# #                            discard_tuned_samples=False,\n",
    "#                             max_treedepth=7,\n",
    "                           )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trace_stat_plot(trace_discrete, 'model_logp', skip_frac=0)\n",
    "trace_stat_plot(trace_discrete, 'diverging', skip_frac=0)\n",
    "trace_stat_plot(trace_discrete, 'step_size', skip_frac=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_fuzzy_dp = build_biallelic_model_fuzzy_fuzzy_dp(g, n, 5)\n",
    "model_fuzzy_dp.observed.set_value(pileup_to_model_input(pileup).reshape((-1, a)))\n",
    "model_fuzzy_dp.alpha.set_value(1e5)\n",
    "model_fuzzy_dp.gamma_hyper.set_value(1)\n",
    "model_fuzzy_dp.pi_hyper.set_value(0)\n",
    "model_fuzzy_dp.rho_hyper.set_value(0)\n",
    "model_fuzzy_dp.epsilon_hyper.set_value(200)\n",
    "\n",
    "with model_fuzzy_dp:\n",
    "    trace_fuzzy_dp = pm.sample(chains=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_discrete_dp = build_biallelic_model_discrete_dp(g, n, 5)\n",
    "model_discrete_dp.observed.set_value(pileup_to_model_input(pileup).reshape((-1, a)))\n",
    "model_discrete_dp.alpha.set_value(1e5)\n",
    "model_discrete_dp.gamma_hyper.set_value(1)\n",
    "model_discrete_dp.pi_hyper.set_value(0)\n",
    "model_discrete_dp.rho_hyper.set_value(0)\n",
    "model_discrete_dp.epsilon_hyper.set_value(200)\n",
    "\n",
    "with model_discrete_dp:\n",
    "    trace_discrete_dp = pm.sample(chains=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mapest_fuzzy = find_MAP_loop(model_fuzzy, trace_fuzzy[-1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mapest_dp = find_MAP_loop(model_dp, trace_dp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trace_discrete.epsilon.mean(0), label='discrete', color='green')\n",
    "plt.plot(trace_fuzzy.epsilon.mean(0), label='fuzzy', color='blue')\n",
    "# plt.plot(mapest_fuzzy['epsilon'], label='fuzzy_mapest', color='darkblue')\n",
    "# plt.plot(trace_fuzzy_dp.epsilon.mean(0), label='fuzzy_dp', color='aqua')\n",
    "# plt.plot(trace_discrete_dp.epsilon.mean(0), label='discrete_dp', color='lightgreen')\n",
    "\n",
    "\n",
    "plt.axhline(1e-2, lw=1, linestyle='--', color='k')\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_stat_plot(trace_fuzzy, 'model_logp')\n",
    "trace_stat_plot(trace_discrete, 'model_logp')\n",
    "# trace_stat_plot(trace_fuzzy_dp, 'model_logp')\n",
    "# trace_stat_plot(trace_discrete_dp, 'model_logp')\n",
    "\n",
    "(\n",
    "    ess(trace_fuzzy.model_logp),\n",
    "    ess(trace_discrete.model_logp),\n",
    "#     ess(trace_fuzzy_dp.model_logp),\n",
    "#     ess(trace_discrete_dp.model_logp),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_permutation_greedy(data, ref, axis, key=None):\n",
    "    index_swap = (0, axis)\n",
    "    data = np.swapaxes(data, *index_swap)\n",
    "    ref = np.swapaxes(ref, *index_swap)\n",
    "    \n",
    "    if key is None:\n",
    "        key = lambda x, y: (np.abs(x - y)**2).sum()\n",
    "\n",
    "    data_idx = np.arange(data.shape[0])\n",
    "    ref_idx = np.arange(ref.shape[0])\n",
    "    \n",
    "    perm = []\n",
    "    for i in ref_idx:\n",
    "        best_data_idx = 0\n",
    "        best_data_loss = np.inf\n",
    "        for j in data_idx:\n",
    "            if j in perm:\n",
    "                continue\n",
    "            loss = key(ref[i], data[j])\n",
    "            if loss < best_data_loss:\n",
    "                best_data_idx = j\n",
    "                best_data_loss = loss\n",
    "        perm.append(best_data_idx)\n",
    "    \n",
    "    for j in data_idx:\n",
    "        if j not in perm:\n",
    "            perm.append(j)\n",
    "    \n",
    "    return perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_expect_fuzzy = np.median(trace_fuzzy['pi'], axis=0)\n",
    "_expect_discrete = np.median(trace_discrete['pi'], axis=0)\n",
    "# _map_fuzzy = mapest_fuzzy['pi']\n",
    "# _expect_fuzzy_dp = np.median(trace_fuzzy_dp['pi'], axis=0)\n",
    "# _expect_discrete_dp = np.median(trace_discrete_dp['pi'], axis=0)\n",
    "\n",
    "permute_discrete = select_permutation_greedy(_expect_discrete, frac, axis=1)\n",
    "permute_fuzzy = select_permutation_greedy(_expect_fuzzy, frac, axis=1)\n",
    "# permute_fuzzy_dp = select_permutation_greedy(_expect_fuzzy_dp, frac, axis=1)\n",
    "# permute_discrete_dp = select_permutation_greedy(_expect_discrete_dp, frac, axis=1)\n",
    "\n",
    "#_map_dp = mapest_dp['pi']\n",
    "\n",
    "pi_plot(frac, pwr=1/2)\n",
    "pi_plot(_expect_discrete[:,permute_discrete], pwr=1/2)\n",
    "# pi_plot(_expect_discrete_dp[:,permute_discrete_dp])\n",
    "pi_plot(_expect_fuzzy[:,permute_fuzzy], pwr=1/2)\n",
    "# pi_plot(_expect_fuzzy_dp[:,permute_fuzzy_dp])\n",
    "# pi_plot(_map_fuzzy[:,permute_fuzzy], pwr=1/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_expect_fuzzy = trace_fuzzy['gamma'].mean(0)\n",
    "_expect_discrete = trace_discrete['gamma'].mean(0)\n",
    "# _map_fuzzy = mapest_fuzzy['gamma']\n",
    "# _expect_fuzzy_dp = trace_fuzzy_dp['gamma'].mean(0)\n",
    "# _expect_discrete_dp = trace_discrete_dp['gamma'].mean(0)\n",
    "\n",
    "#_map_dp = mapest_dp['gamma']\n",
    "\n",
    "\n",
    "gamma_plot(haplotype)\n",
    "gamma_plot(_expect_discrete[:,permute_discrete])\n",
    "# gamma_plot(_expect_discrete_dp[:,permute_discrete_dp])\n",
    "gamma_plot(_expect_fuzzy[:,permute_fuzzy])\n",
    "# gamma_plot(_expect_fuzzy_dp[:,permute_fuzzy_dp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_true = np.concatenate([\n",
    "    np.zeros((g, trace_fuzzy['gamma'].shape[2] - haplotype.shape[1], a)),\n",
    "    haplotype\n",
    "], axis=1)\n",
    "_loss_f = lambda d: np.sqrt((np.square(d)).mean())\n",
    "\n",
    "print('discrete', _loss_f((np.mean(trace_discrete.gamma[:,:,permute_discrete], axis=0) - _true)[:,1,0]))\n",
    "print('fuzzy', _loss_f((np.mean(trace_fuzzy.gamma[:,:,permute_fuzzy], axis=0) - _true)[:,1,0]))\n",
    "# print('fuzzy_discretized', _loss_f((np.mean(trace_fuzzy.gamma[:,:,permute_fuzzy] > 0.5, axis=0) - _true)[:,1,0]))\n",
    "# print('fuzzy_mapest', _loss_f((mapest_fuzzy['gamma'][:,permute_fuzzy] - _true)[:,1,0]))\n",
    "# print('fuzzy_dp', _loss_f((np.mean(trace_fuzzy_dp.gamma[:,:,permute_fuzzy_dp], axis=0) - _true)[:,1,0]))\n",
    "# print('discrete_dp', _loss_f((np.mean(trace_discrete_dp.gamma[:,:,permute_discrete_dp], axis=0) - _true)[:,1,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_true = np.concatenate([\n",
    "    np.zeros((g, trace_fuzzy['gamma'].shape[2] - haplotype.shape[1], a)),\n",
    "    haplotype\n",
    "], axis=1)\n",
    "_loss_f = lambda d: np.abs(d).mean()\n",
    "\n",
    "print('discrete', _loss_f((np.mean(trace_discrete.gamma[:,:,permute_discrete], axis=0) - _true)[:,1,0]))\n",
    "print('fuzzy', _loss_f((np.mean(trace_fuzzy.gamma[:,:,permute_fuzzy], axis=0) - _true)[:,1,0]))\n",
    "# print('fuzzy_discretized', _loss_f((np.mean(trace_fuzzy.gamma[:,:,permute_fuzzy] > 0.5, axis=0) - _true)[:,1,0]))\n",
    "# print('fuzzy_mapest', _loss_f((mapest_fuzzy['gamma'][:,permute_fuzzy] - _true)[:,1,0]))\n",
    "# print('fuzzy_dp', _loss_f((np.mean(trace_fuzzy_dp.gamma[:,:,permute_fuzzy_dp], axis=0) - _true)[:,1,0]))\n",
    "# print('discrete_dp', _loss_f((np.mean(trace_discrete_dp.gamma[:,:,permute_discrete_dp], axis=0) - _true)[:,1,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1\n",
    "_true = frac[:,j]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 10))\n",
    "\n",
    "ax.scatter(_true, range(n), color='k', marker='x', label='true')\n",
    "#ax.scatter(mapest_fuzzy['pi'][:,permute_fuzzy][:,j], range(n), color='g', marker='.', label='fuzzy-mapest')\n",
    "\n",
    "\n",
    "for pi, name, color, offset in [\n",
    "                        (trace_fuzzy.pi[:,:,permute_fuzzy], 'fuzzy', 'blue', +0.1),\n",
    "#                         (trace_fuzzy_dp.pi[:,:,permute_fuzzy_dp], 'fuzzy_dp', 'aqua', +0.2),\n",
    "                        (trace_discrete.pi[:,:,permute_discrete], 'discrete', 'green', -0.1),\n",
    "#                         (trace_discrete_dp.pi[:,:,permute_discrete_dp], 'discrete_dp', 'lightgreen', -0.2),\n",
    "                       ]:\n",
    "    ax.scatter(np.quantile(pi, 0.5, axis=0)[:,j], np.arange(n) + offset, color=color, marker='^', label=name)\n",
    "    print(name, np.sqrt(np.mean(np.square(np.quantile(pi, 0.5, axis=0)[:,j] - _true))))\n",
    "#    plt.scatter(np.mean(pi, axis=0)[:,0], range(n), color=color, marker='o')\n",
    "    ax.hlines(np.arange(n) + offset, np.quantile(pi, 0.25, axis=0)[:,j], np.quantile(pi, 0.75, axis=0)[:,j], lw=1, color=color)\n",
    "    ax.hlines(np.arange(n) + offset, np.quantile(pi, 0.05, axis=0)[:,j], np.quantile(pi, 0.95, axis=0)[:,j], lw=0.5, color=color)\n",
    "    ax.hlines(np.arange(n) + offset, np.quantile(pi, 0.01, axis=0)[:,j], np.quantile(pi, 0.99, axis=0)[:,j], lw=0.25, color=color)\n",
    "ax.legend(bbox_to_anchor=(1.25, 1))\n",
    "#ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0\n",
    "_true = frac[:,j]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 10))\n",
    "\n",
    "ax.scatter(_true, range(n), color='k', marker='x', label='true')\n",
    "#ax.scatter(mapest_fuzzy['pi'][:,permute_fuzzy][:,j], range(n), color='g', marker='.', label='fuzzy-mapest')\n",
    "\n",
    "\n",
    "for pi, name, color, offset in [\n",
    "                        (trace_fuzzy.pi[:,:,permute_fuzzy], 'fuzzy', 'blue', +0.1),\n",
    "#                         (trace_fuzzy_dp.pi[:,:,permute_fuzzy_dp], 'fuzzy_dp', 'aqua', +0.2),\n",
    "                        (trace_discrete.pi[:,:,permute_discrete], 'discrete', 'green', -0.1),\n",
    "#                         (trace_discrete_dp.pi[:,:,permute_discrete_dp], 'discrete_dp', 'lightgreen', -0.2),\n",
    "                       ]:\n",
    "    ax.scatter(np.quantile(pi, 0.5, axis=0)[:,j], np.arange(n) + offset, color=color, marker='^', label=name)\n",
    "    print(name, np.sqrt(np.mean(np.square(np.quantile(pi, 0.5, axis=0)[:,j] - _true))))\n",
    "#    plt.scatter(np.mean(pi, axis=0)[:,0], range(n), color=color, marker='o')\n",
    "    ax.hlines(np.arange(n) + offset, np.quantile(pi, 0.25, axis=0)[:,j], np.quantile(pi, 0.75, axis=0)[:,j], lw=1, color=color)\n",
    "    ax.hlines(np.arange(n) + offset, np.quantile(pi, 0.05, axis=0)[:,j], np.quantile(pi, 0.95, axis=0)[:,j], lw=0.5, color=color)\n",
    "    ax.hlines(np.arange(n) + offset, np.quantile(pi, 0.01, axis=0)[:,j], np.quantile(pi, 0.99, axis=0)[:,j], lw=0.25, color=color)\n",
    "ax.legend(bbox_to_anchor=(1.25, 1))\n",
    "#ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.scatter(trace_fuzzy['pi'][:,0,1], trace_fuzzy['pi'][:,0,2], s=3)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.ylim(1e-4)\n",
    "plt.xlim(1e-4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(np.log(trace_fuzzy['pi'][:,5,permute_fuzzy[1]] / trace_fuzzy['pi'][:,5,permute_fuzzy[2]]), '.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.kdeplot(np.log(trace_fuzzy['pi'][:,5,permute_fuzzy[1]] / trace_fuzzy['pi'][:,5,permute_fuzzy[2]]))\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.xlim(1e-5)\n",
    "# plt.ylim(1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype Desman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import desman\n",
    "\n",
    "desman??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SimulationReplicate:\n",
    "    frac: np.ndarray\n",
    "    haplo: np.ndarray\n",
    "    pileup: np.ndarray\n",
    "    model: pm.Model\n",
    "    trace: pm.sampling.MultiTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_pileup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell (and specifically the last line) results in a segmentation fault.\n",
    "\n",
    "from desman import HaploSNP_Sampler, Init_NMFT\n",
    "\n",
    "prng = np.random.RandomState(1)\n",
    "\n",
    "dm_pileup = (\n",
    "    np.concatenate(\n",
    "        [pileup_to_model_input(pileup),\n",
    "         np.zeros_like(pileup_to_model_input(pileup))],\n",
    "        axis=-1\n",
    "    )\n",
    "    .swapaxes(0, 1)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "dm_init = Init_NMFT.Init_NMFT(dm_pileup, 2, prng)\n",
    "dm_init.factorize()\n",
    "tau_est = dm_init.get_tau()\n",
    "\n",
    "dm_smplr = HaploSNP_Sampler.HaploSNP_Sampler(dm_pileup, 2, prng)\n",
    "dm_smplr.tau = np.copy(dm_init.get_tau(), order='C')\n",
    "dm_smplr.updateTauIndices()\n",
    "dm_smplr.gamma = np.copy(dm_init.get_gamma(), order='C')\n",
    "#dm_smplr.eta = np.copy(dm_init.eta, order='C')\n",
    "dm_smplr.update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}